{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"plops\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "config_schema = OrderedDict()\n",
    "config_schema = [\n",
    "    ('timestamp', 'string'),\n",
    "    ('occupancy', 'INT'),\n",
    "    ('blockface_name', 'STRING'),\n",
    "    ('side_of_street', 'STRING'),\n",
    "    ('station_id', 'INT'),\n",
    "    ('time_limit_category', 'STRING'),\n",
    "    ('space_count', 'INT'),\n",
    "    ('area', 'STRING'),\n",
    "    ('subarea', 'STRING'),\n",
    "    ('rate', 'STRING'),\n",
    "    ('category', 'STRING'),\n",
    "    ('location', 'STRING'),\n",
    "    ('emptycol1','STRING'),\n",
    "    ('emptycol2','STRING'),\n",
    "    ('emptycol3','STRING'),\n",
    "    ('emptycol4','STRING'),\n",
    "    ('emptycol5','STRING')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'timestamp string, occupancy INT, blockface_name STRING, side_of_street STRING, station_id INT, time_limit_category STRING, space_count INT, area STRING, subarea STRING, rate STRING, category STRING, location STRING, emptycol1 STRING, emptycol2 STRING, emptycol3 STRING, emptycol4 STRING, emptycol5 STRING'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = \", \".join([\"{} {}\".format(col, type) for col, type in config_schema])\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\n",
    "    #\"s3a://project.datasets/Last_48_hours.csv\", header=True, mode=\"DROPMALFORMED\", schema=schema\n",
    "    #\"s3a://project.datasets/last_48h.csv.gz\", header=True, mode=\"DROPMALFORMED\", schema=schema\n",
    "    \"s3a://project.datasets/2019-Paid-Parking-Occupancy.csv.gz\", header=True, mode=\"DROPMALFORMED\", schema=schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(timestamp,StringType,true),StructField(occupancy,IntegerType,true),StructField(blockface_name,StringType,true),StructField(side_of_street,StringType,true),StructField(station_id,IntegerType,true),StructField(time_limit_category,StringType,true),StructField(space_count,IntegerType,true),StructField(area,StringType,true),StructField(subarea,StringType,true),StructField(rate,StringType,true),StructField(category,StringType,true),StructField(location,StringType,true),StructField(emptycol1,StringType,true),StructField(emptycol2,StringType,true),StructField(emptycol3,StringType,true),StructField(emptycol4,StringType,true),StructField(emptycol5,StringType,true)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"blockface_name\", \n",
    "             \"side_of_street\", \n",
    "             \"time_limit_category\", \n",
    "             \"space_count\", \n",
    "             \"area\", \n",
    "             \"subarea\",\n",
    "             \"rate\",\n",
    "             \"category\",\n",
    "             \"emptycol1\",\n",
    "             \"emptycol2\",\n",
    "             \"emptycol3\",\n",
    "             \"emptycol4\",\n",
    "             \"emptycol5\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- occupancy: integer (nullable = true)\n",
      " |-- station_id: integer (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"timestamp\", F.to_timestamp(df.timestamp, format=\"mm/dd/yyyy hh:mm:ss a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- occupancy: integer (nullable = true)\n",
      " |-- station_id: integer (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('day_of_week', F.dayofweek(df.timestamp))\n",
    "df = df.withColumn('hour', F.hour(df.timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create New DataFrame\n",
    "# from pyspark.sql.types import (StructType,\n",
    "#                                TimestampType,\n",
    "#                                IntegerType,\n",
    "#                                DoubleType)\n",
    "# field = [\n",
    "#     StructField('DateTime', TimestampType(), True),\n",
    "#     StructField('StationID', StringType(), True),\n",
    "#     StructField('AveOpenSpots', IntegerType(), True),\n",
    "#     StructField('AveOpenRate', DoubleType(), True),\n",
    "#     StructField('GroupByPeriod', StringType(), True),\n",
    "#     StructField('Location', StringType(), True)\n",
    "# ]\n",
    "# new_schema = StructType(field)\n",
    "# df_ave = sqlContext.createDataFrame(sc.emptyRDD(), new_schema)\n",
    "# df_ave.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- occupancy: integer (nullable = true)\n",
      " |-- station_id: integer (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import DataFrameWriter\n",
    "my_writer = DataFrameWriter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'occupancy'\n",
    "hostname = 'ec2-52-39-242-144.us-west-2.compute.amazonaws.com'\n",
    "url_connect = \"jdbc:postgresql://{hostname}:5432/{db}\".format(hostname=hostname, db=database_name)\n",
    "\n",
    "table = \"spark_output_occupancy\"\n",
    "mode = \"overwrite\"\n",
    "properties = {\"user\":\"spark_user\", \n",
    "              \"password\":os.environ['POSTGRES_PASS'],\n",
    "              \"driver\": \"org.postgresql.Driver\"\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_writer.jdbc(url_connect, table, mode, properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
