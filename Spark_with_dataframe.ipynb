{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"plops\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "config_schema = OrderedDict()\n",
    "config_schema = [\n",
    "    ('OccupancyDateTime', 'STRING'),\n",
    "    ('PaidOccupancy', 'INT'),\n",
    "    ('BlockfaceName', 'STRING'),\n",
    "    ('SideOfStreet', 'STRING'),\n",
    "    ('SourceElementKey', 'INT'),\n",
    "    ('ParkingTimeLimitCategory', 'STRING'),\n",
    "    ('ParkingSpaceCount', 'INT'),\n",
    "    ('PaidParkingArea', 'STRING'),\n",
    "    ('PaidParkingSubArea', 'STRING'),\n",
    "    ('PaidParkingRate', 'STRING'),\n",
    "    ('ParkingCategory', 'STRING'),\n",
    "    ('Location', 'STRING'),\n",
    "    ('emptycol1','STRING'),\n",
    "    ('emptycol2','STRING'),\n",
    "    ('emptycol3','STRING'),\n",
    "    ('emptycol4','STRING'),\n",
    "    ('emptycol5','STRING')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OccupancyDateTime STRING, PaidOccupancy INT, BlockfaceName STRING, SideOfStreet STRING, SourceElementKey INT, ParkingTimeLimitCategory STRING, ParkingSpaceCount INT, PaidParkingArea STRING, PaidParkingSubArea STRING, PaidParkingRate STRING, ParkingCategory STRING, Location STRING, emptycol1 STRING, emptycol2 STRING, emptycol3 STRING, emptycol4 STRING, emptycol5 STRING'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = \", \".join([\"{} {}\".format(col, type) for col, type in config_schema])\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\n",
    "    \"s3a://project.datasets/Last_48_hours.csv\", header=True, mode=\"DROPMALFORMED\", schema=schema\n",
    "    #\"s3a://project.datasets/last_48h.csv.gz\", header=True, mode=\"DROPMALFORMED\", schema=schema\n",
    "    #\"s3a://project.datasets/2019-Paid-Parking-Occupancy.csv.gz\", header=True, mode=\"DROPMALFORMED\", schema=schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(OccupancyDateTime,StringType,true),StructField(PaidOccupancy,IntegerType,true),StructField(BlockfaceName,StringType,true),StructField(SideOfStreet,StringType,true),StructField(SourceElementKey,IntegerType,true),StructField(ParkingTimeLimitCategory,StringType,true),StructField(ParkingSpaceCount,IntegerType,true),StructField(PaidParkingArea,StringType,true),StructField(PaidParkingSubArea,StringType,true),StructField(PaidParkingRate,StringType,true),StructField(ParkingCategory,StringType,true),StructField(Location,StringType,true),StructField(emptycol1,StringType,true),StructField(emptycol2,StringType,true),StructField(emptycol3,StringType,true),StructField(emptycol4,StringType,true),StructField(emptycol5,StringType,true)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+------------+----------------+------------------------+-----------------+---------------+------------------+---------------+---------------+--------------------+---------+---------+---------+---------+---------+\n",
      "|   OccupancyDateTime|PaidOccupancy|       BlockfaceName|SideOfStreet|SourceElementKey|ParkingTimeLimitCategory|ParkingSpaceCount|PaidParkingArea|PaidParkingSubArea|PaidParkingRate|ParkingCategory|            Location|emptycol1|emptycol2|emptycol3|emptycol4|emptycol5|\n",
      "+--------------------+-------------+--------------------+------------+----------------+------------------------+-----------------+---------------+------------------+---------------+---------------+--------------------+---------+---------+---------+---------+---------+\n",
      "|03/05/2019 10:14:...|            2|TERRY AVE BETWEEN...|          NE|           35730|                     240|                5| Denny Triangle|             North|           null|   Paid Parking|POINT (47.6159364...|     null|     null|     null|     null|     null|\n",
      "+--------------------+-------------+--------------------+------------+----------------+------------------------+-----------------+---------------+------------------+---------------+---------------+--------------------+---------+---------+---------+---------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"BlockfaceName\", \n",
    "             \"SideOfStreet\", \n",
    "             \"ParkingTimeLimitCategory\", \n",
    "             \"ParkingSpaceCount\", \n",
    "             \"PaidParkingArea\", \n",
    "             \"PaidParkingSubArea\",\n",
    "             \"PaidParkingRate\",\n",
    "             \"ParkingCategory\",\n",
    "             \"emptycol1\",\n",
    "             \"emptycol2\",\n",
    "             \"emptycol3\",\n",
    "             \"emptycol4\",\n",
    "             \"emptycol5\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OccupancyDateTime: string (nullable = true)\n",
      " |-- PaidOccupancy: integer (nullable = true)\n",
      " |-- SourceElementKey: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"OccupancyDateTime\", F.to_timestamp(df.OccupancyDateTime, format=\"mm/dd/yyyy hh:mm:ss a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OccupancyDateTime: timestamp (nullable = true)\n",
      " |-- PaidOccupancy: integer (nullable = true)\n",
      " |-- SourceElementKey: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+----------------+--------------------+\n",
      "|  OccupancyDateTime|PaidOccupancy|SourceElementKey|            Location|\n",
      "+-------------------+-------------+----------------+--------------------+\n",
      "|2019-01-05 10:14:00|            2|           35730|POINT (47.6159364...|\n",
      "+-------------------+-------------+----------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('DayOfWeek', F.dayofweek(df.OccupancyDateTime))\n",
    "df = df.withColumn('Hour', F.hour(df.OccupancyDateTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+----------------+--------------------+---------+----+\n",
      "|  OccupancyDateTime|PaidOccupancy|SourceElementKey|            Location|DayOfWeek|Hour|\n",
      "+-------------------+-------------+----------------+--------------------+---------+----+\n",
      "|2019-01-05 10:14:00|            2|           35730|POINT (47.6159364...|        7|  10|\n",
      "|2019-01-05 18:39:00|           11|           34214|POINT (47.6058076...|        7|  18|\n",
      "|2019-01-05 09:06:00|            4|           59246|POINT (47.6187126...|        7|   9|\n",
      "|2019-01-05 15:34:00|            3|            1278|POINT (47.6214913...|        7|  15|\n",
      "|2019-01-04 14:23:00|            1|            7250|POINT (47.6062128...|        6|  14|\n",
      "|2019-01-05 12:59:00|            4|           76201|POINT (47.6226588...|        7|  12|\n",
      "|2019-01-05 09:45:00|            5|            7265|POINT (47.6182771...|        7|   9|\n",
      "|2019-01-04 15:54:00|            2|           80545|POINT (47.6232851...|        6|  15|\n",
      "|2019-01-05 08:21:00|            2|           12550|POINT (47.6230668...|        7|   8|\n",
      "|2019-01-05 12:42:00|            3|           36094|POINT (47.6023450...|        7|  12|\n",
      "+-------------------+-------------+----------------+--------------------+---------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create New DataFrame\n",
    "# from pyspark.sql.types import (StructType,\n",
    "#                                TimestampType,\n",
    "#                                IntegerType,\n",
    "#                                DoubleType)\n",
    "# field = [\n",
    "#     StructField('DateTime', TimestampType(), True),\n",
    "#     StructField('StationID', StringType(), True),\n",
    "#     StructField('AveOpenSpots', IntegerType(), True),\n",
    "#     StructField('AveOpenRate', DoubleType(), True),\n",
    "#     StructField('GroupByPeriod', StringType(), True),\n",
    "#     StructField('Location', StringType(), True)\n",
    "# ]\n",
    "# new_schema = StructType(field)\n",
    "# df_ave = sqlContext.createDataFrame(sc.emptyRDD(), new_schema)\n",
    "# df_ave.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OccupancyDateTime: timestamp (nullable = true)\n",
      " |-- PaidOccupancy: integer (nullable = true)\n",
      " |-- SourceElementKey: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- Hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import DataFrameWriter\n",
    "my_writer = DataFrameWriter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_connect = \"jdbc:postgresql://ec2-52-39-242-144.us-west-2.compute.amazonaws.com:5432/occupancy\"\n",
    "table = \"hist_occupancy\"\n",
    "mode = \"overwrite\"\n",
    "properties = {\"user\":\"spark_user\", \n",
    "              \"password\":os.environ['POSTGRES_PASS'],\n",
    "              \"driver\": \"org.postgresql.Driver\"\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_writer.jdbc(url_connect, table, mode, properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
